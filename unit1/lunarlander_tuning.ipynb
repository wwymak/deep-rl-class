{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724e4f17-1516-4918-9674-97db165ad9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
    "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f3c806-1341-43f3-8a08-8e66867915c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_steps=2048, n_epochs=10, batch_size=256, discount_factor_gamma=0.99, total_timesteps=1e6):\n",
    "    training_env= make_vec_env('LunarLander-v2', n_envs=16)\n",
    "    model = PPO(\n",
    "        policy = 'MlpPolicy',\n",
    "        env = training_env,\n",
    "        n_steps = n_steps,\n",
    "        batch_size = batch_size,\n",
    "        n_epochs = n_epochs,\n",
    "        gamma = discount_factor_gamma,\n",
    "        gae_lambda = 0.98,\n",
    "        ent_coef = 0.01,\n",
    "        verbose=0)\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "    eval_env = gym.make(\"LunarLander-v2\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "    \n",
    "    return model, mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f89d55-43c7-40b2-94f6-5f395ba47edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_steps = [512, 1024, 2048,]\n",
    "# n_epochs=[5,10, 20]\n",
    "# discount_factor_gamma = [0.95, 0.99, 0.999]\n",
    "\n",
    "n_steps = [1024]\n",
    "n_epochs=[20]\n",
    "discount_factor_gamma = [0.999]\n",
    "\n",
    "combinations = list(product(n_steps, n_epochs, discount_factor_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec73c93-4735-4ac2-b1cd-32ecad56d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      "{'n_steps': 1024, 'n_epochs': 20, 'discount_factor_gamma': 0.999}\n",
      "reward: 264.06695057134584 +/- 14.82053438797129\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "best_mean_reward = 0\n",
    "best_std_reward = 1000\n",
    "best_model=None\n",
    "best_params = None\n",
    "\n",
    "for c in combinations:\n",
    "    steps = c[0]\n",
    "    epochs = c[1]\n",
    "    discount = c[2]\n",
    "    params = {\n",
    "        'n_steps': steps,\n",
    "        'n_epochs': epochs,\n",
    "        'discount_factor_gamma': discount,        \n",
    "    }\n",
    "    model, mean_reward, std_reward = train_model(**params)\n",
    "    print('params:')\n",
    "    print(params)\n",
    "    print(f'reward: {mean_reward} +/- {std_reward}')\n",
    "    results.append({**params, **{'mean_reward': mean_reward, 'std_reward': std_reward}})\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    df.to_csv('lunar-tuning-results.csv', index=None)\n",
    "    \n",
    "    if mean_reward > best_mean_reward:\n",
    "        best_model = model\n",
    "        best_mean_reward = mean_reward\n",
    "        best_std_reward = std_reward\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5d6b15-348e-4358-9343-001bc22d9672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ„¹ This function will save, evaluate, generate a video of your agent,\n",
      "create a model card and push everything to the hub. It might take up to 1min.\n",
      "This is a work in progress: If you encounter a bug, please open an issue and use\n",
      "push_to_hub instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/site-packages/huggingface_hub/hf_api.py:79: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.7. Pass `repo_id` instead.\n",
      "  warnings.warn(\n",
      "/home/wwymak/code_experiments/deep-rl-class/unit1/hub/ppo-LunarLander-v2 is already a clone of https://huggingface.co/wwymak/ppo-LunarLander-v2. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to /home/wwymak/code_experiments/deep-rl-class/unit1/-step-0-to-step-1000.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 10.3.0 (conda-forge gcc 10.3.0-16)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1650807798678/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1650807798678/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-demuxer=dash --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-vaapi --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-libvpx --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1650807798678/_build_env/bin/pkg-config\n",
      "  libavutil      57. 17.100 / 57. 17.100\n",
      "  libavcodec     59. 18.100 / 59. 18.100\n",
      "  libavformat    59. 16.100 / 59. 16.100\n",
      "  libavdevice    59.  4.100 / 59.  4.100\n",
      "  libavfilter     8. 24.100 /  8. 24.100\n",
      "  libswscale      6.  4.100 /  6.  4.100\n",
      "  libswresample   4.  3.100 /  4.  3.100\n",
      "  libpostproc    56.  3.100 / 56.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './test.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.16.100\n",
      "  Duration: 00:00:20.02, start: 0.000000, bitrate: 84 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 600x400, 79 kb/s, 50 fps, 50 tbr, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55dd236a8200] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55dd236a8200] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55dd236a8200] 264 - core 161 r3030M 8bd6d28 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'replay.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.16.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 600x400, q=2-31, 50 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame= 1001 fps=0.0 q=-1.0 Lsize=     197kB time=00:00:19.96 bitrate=  80.8kbits/s speed=47.5x    \n",
      "video:184kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 6.752842%\n",
      "[libx264 @ 0x55dd236a8200] frame I:5     Avg QP:10.34  size:  1794\n",
      "[libx264 @ 0x55dd236a8200] frame P:261   Avg QP:22.37  size:   259\n",
      "[libx264 @ 0x55dd236a8200] frame B:735   Avg QP:24.51  size:   152\n",
      "[libx264 @ 0x55dd236a8200] consecutive B-frames:  0.6%  2.8%  5.1% 91.5%\n",
      "[libx264 @ 0x55dd236a8200] mb I  I16..4: 85.4%  8.9%  5.7%\n",
      "[libx264 @ 0x55dd236a8200] mb P  I16..4:  0.2%  0.4%  0.2%  P16..4:  1.7%  0.5%  0.2%  0.0%  0.0%    skip:96.7%\n",
      "[libx264 @ 0x55dd236a8200] mb B  I16..4:  0.1%  0.0%  0.1%  B16..8:  2.4%  0.5%  0.1%  direct: 0.1%  skip:96.8%  L0:55.7% L1:43.0% BI: 1.3%\n",
      "[libx264 @ 0x55dd236a8200] 8x8 transform intra:20.3% inter:11.8%\n",
      "[libx264 @ 0x55dd236a8200] coded y,uvDC,uvAC intra: 10.1% 17.5% 16.5% inter: 0.2% 0.2% 0.2%\n",
      "[libx264 @ 0x55dd236a8200] i16 v,h,dc,p: 82% 13%  5%  0%\n",
      "[libx264 @ 0x55dd236a8200] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 17% 72%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55dd236a8200] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 14% 58%  2%  3%  2%  3%  2%  3%\n",
      "[libx264 @ 0x55dd236a8200] i8c dc,h,v,p: 91%  6%  3%  0%\n",
      "[libx264 @ 0x55dd236a8200] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55dd236a8200] ref P L0: 64.7%  1.7% 22.9% 10.6%\n",
      "[libx264 @ 0x55dd236a8200] ref B L0: 66.0% 29.1%  5.0%\n",
      "[libx264 @ 0x55dd236a8200] ref B L1: 91.6%  8.4%\n",
      "[libx264 @ 0x55dd236a8200] kb/s:75.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ„¹ Pushing repo ppo-LunarLander-v2 to the Hugging Face Hub\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725b9aac2f89414b8cde14c6ac14df3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file replay.mp4:  16%|#6        | 32.0k/197k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/wwymak/anaconda3/envs/deeprl/lib/python3.8/site-packages/huggingface_hub/repository.py\", line 379, in output_progress\n",
      "    state, file_progress, byte_progress, filename = line.split()\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "remote: Enforcing permissions...        \n",
      "remote: Allowed refs: all        \n",
      "To https://huggingface.co/wwymak/ppo-LunarLander-v2\n",
      "   8e6ae38..d5487bb  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ„¹ Your model is pushed to the hub. You can view your model here:\n",
      "https://huggingface.co/wwymak/ppo-LunarLander-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/wwymak/ppo-LunarLander-v2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "# TODO: Define the name of the environment\n",
    "env_id = \"LunarLander-v2\"\n",
    "# Create the evaluation env\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "model_name=\"lunar v2\"\n",
    "\n",
    "# TODO: Define the model architecture we used\n",
    "model_architecture = \"PPO\"\n",
    "\n",
    "## TODO: Define a repo_id\n",
    "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "repo_id = \"wwymak/ppo-LunarLander-v2\"\n",
    "\n",
    "## TODO: Define the commit message\n",
    "commit_message = f\"lunar lander tuned, 1e6 timesteps, params: {best_params}\"\n",
    "\n",
    "# method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub\n",
    "package_to_hub(model=best_model, # Our trained model\n",
    "               model_name=model_name, # The name of our trained model \n",
    "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
    "               env_id=env_id, # Name of the environment\n",
    "               eval_env=eval_env, # Evaluation Environment\n",
    "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "               commit_message=commit_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302b362-462a-4a56-b748-73708679ff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeprl]",
   "language": "python",
   "name": "conda-env-deeprl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
